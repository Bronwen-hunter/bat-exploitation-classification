
## Functions used to carry out experiments with naive-bayes and neural network classifiers ##

import pandas as pd
import random

from sklearn.feature_extraction.text import HashingVectorizer
from sklearn.metrics import precision_recall_fscore_support, accuracy_score
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import make_pipeline
import numpy as np

from keras.models import Sequential, load_model
from keras.layers import Dense, Dropout
from keras.callbacks import ModelCheckpoint
from keras.backend import clear_session
import keras

import nltk
nltk.download("punkt")
nltk.download('stopwords')
from nltk.corpus import stopwords

class NB_classifier():

    ''' Class that contains functions to train and test a naive bayes classification '''

    def __init__(self, xtrain, ytrain, xtest, ytest):
        self.xtrain = xtrain
        self.ytrain = ytrain
        self.xtest = xtest
        self.ytest = ytest
        self.model = self.train_classifier()
    

    def train_classifier(self):
        nb_model = make_pipeline(HashingVectorizer(n_features=10000, alternate_sign=False), MultinomialNB())
        nb_model.fit(self.xtrain, self.ytrain)
        preds = nb_model.predict([NB_classifier.preprocess_nb(string.lower()) for string in self.xtest])
        return nb_model, preds

    def evaluate_classifier(self, preds):
        precision, recall, fscore, support = precision_recall_fscore_support(self.ytest, preds, average='binary', pos_label=1)
        accuracy = accuracy_score(self.ytest, preds)
        return precision, recall, fscore, support, accuracy

    def preprocess_nb(string):
        string = string.replace('\n', ' ')
        stop= stopwords.words('english')
        words = nltk.word_tokenize(string)
        words_nopunct = [word for word in words if word.isalpha()]
        words_nostop = [word for word in words_nopunct if word not in stop]
        return ' '.join(words_nostop)


class feedforward_NN():
    def __init__(self):
        pass
    
    def compile_model(self, n_classes=2, n_features=0, **extras):

        ''' builds a simple 3 layer feedforward model'''
        
        if n_classes == 2:
            n_outputs = n_classes - 1
        else:
            n_outputs = n_classes

        model = Sequential()
        model.add(Dense(1000, input_dim=n_features, activation='relu'))
        model.add(Dropout(0.5))
        model.add(Dense(100, activation='relu'))
        model.add(Dropout(0.5))
        model.add(Dense(10, activation='relu'))
        model.add(Dropout(0.5))
        model.add(Dense(n_outputs, activation='sigmoid'))

        model.compile(optimizer='adam', loss='binary_crossentropy',
                      metrics=['binary_accuracy', 'mse'])

        return model
    
    def prepare_data(self, x_train, y_train, x_test, y_test):
      vectorizer = HashingVectorizer(n_features=10000)
      X_train_V = vectorizer.transform(x_train).toarray()
      X_test_V  = vectorizer.transform(x_test).toarray()
      y_train_a= np.array(y_train)
      y_test_a = np.array(y_test)
      return X_train_V, X_test_V, y_train_a, y_test_a, 
    
    def train_model(self, model, x_train, y_train, xdev, ydev, epochs=1, model_filepath='', batch_size=50):
      CP = ModelCheckpoint(model_filepath, monitor='val_binary_accuracy', verbose=1, save_best_only=True, mode='auto')
      model.fit(x_train, y_train, epochs=epochs, verbose=True, validation_data=(xdev, ydev), batch_size=50, callbacks=CP)
      return model
    
    def preprocess_nn(string):
      string = string.replace('\n', ' ')
      stop= stopwords.words('english')
      words = nltk.word_tokenize(string)
      words_nopunct = [word for word in words if word.isalpha()]
      words_nostop = [word for word in words_nopunct if word not in stop]
      return ' '.join(words_nostop)
    

class Metrics(object):

    '''module to get precision, recall and fscore over predictions'''

    def __init__(self):
        pass

    def get_prec_rec_fscore(self, y_true, y_pred, threshold=0.5):
        '''
        calculates the precision, recall, fscore and support
        of a binary output classifier
        '''
        binary_labels = [0, 1]
        y_pred = np.piecewise(y_pred, [y_pred <= threshold,
                                          y_pred > threshold],
                                 binary_labels)

        precision, recall, fscore, support = precision_recall_fscore_support(
                                                y_true, y_pred,
                                                average='binary',
                                                pos_label=1)
        
        accuracy = accuracy_score(y_true, y_pred)

        return precision, recall, fscore, support, accuracy

def run_experiments_NB(xtrain, ytrain, xtest, ytest, min, max, increments, numberofruns):

    ''' Experimenting with different training sizes for the naive bayes classifier'''

    df = pd.DataFrame()
    count = 0
    xtrain = [NB_classifier.preprocess_nb(string.lower()) for string in xtrain]
    xtest = [NB_classifier.preprocess_nb(string.lower()) for string in xtest]
    samples = [i for i in range(min, max+increments, increments)]
    for run in range(numberofruns):
        for i, sample in enumerate(samples):
            count +=1
            random.seed(count)
            indices = random.sample(list(range(len(xtrain))), sample)
            xnew = [xtrain[index]for index  in indices]
            ynew = [ytrain[index] for index  in indices]
            model = NB_classifier(xnew, ynew, xtest, ytest)
            model1, preds = model.train_classifier()
            precision, recall, fscore, support, accuracy = model.evaluate_classifier(preds)
            df.loc[count, 'model'] = "naive_bayes"
            df.loc[count, 'run'] = run
            df.loc[count, 'training_size'] = sample
            df.loc[count, 'precision'] = precision
            df.loc[count, 'recall'] = recall
            df.loc[count, 'fscore'] = fscore
            df.loc[count, 'accuracy'] = accuracy
            print("Trained model with {} training points {}/{}".format(sample, run+1, numberofruns))
    return df

def run_experiments_NN(xtrain, ytrain, xtest, ytest, min, max, increments, filepath, numberofruns):

    ''' Experimenting with different training sizes for the neural network classifier'''

    df = pd.DataFrame()
    count = 0
    print("Preprocessing datasets...")
    xtrain = [feedforward_NN.preprocess_nn(x.lower()) for x in xtrain]
    xtest = [feedforward_NN.preprocess_nn(x.lower()) for x in xtest]
    print("Finished preprocessing datasets")
    samples = [i for i in range(min, max+increments, increments)]
    for run in range(numberofruns):
        for i, sample in enumerate(samples):
            count +=1
            random.seed(count)
            indices = random.sample(list(range(len(xtrain))), sample)
            xnew = [xtrain[index]for index in indices]
            ynew = [ytrain[index] for index in indices]
            model_class = feedforward_NN()
            X_train_V, X_test_V, y_train_a, y_test_a  = model_class.prepare_data(xnew, ynew, xtest, ytest)
            model1 = model_class.compile_model(n_classes=2, n_features=X_train_V.shape[1])
            model_class.train_model(model1, X_train_V, y_train_a, X_test_V, y_test_a, epochs=10, model_filepath=filepath, batch_size=50)
            metrics = Metrics()
            predictions = model1.predict(X_test_V)
            precision, recall, fscore, support, accuracy = metrics.get_prec_rec_fscore(ytest, predictions)
            df.loc[count, 'model'] = "feed-forward-nn"
            df.loc[count, 'run'] = run
            df.loc[count, 'training_size'] = sample
            df.loc[count, 'recall'] = recall
            df.loc[count, 'fscore'] = fscore
            df.loc[count, 'precision'] = precision
            df.loc[count, 'accuracy'] = accuracy
            clear_session()
    return df